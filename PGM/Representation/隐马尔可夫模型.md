在概率图中引入 时间 的尺度，对模型在不同时刻下的状态变化，成为动态的概率图（Template Model）。

 要定义系统在时间尺度上的演化，就需要引入系统状态（system state）的概念，每一时刻的**系统状态**都是表示系统属性的**随机变量**。 



 将图模型中的结点用表示时间流动的有向边连接起来，得到的是**动态贝叶斯网络**（dynamic Bayesian nework），其最简单的实现是**隐马尔可夫模型**（hidden Markov model）。 



## 隐马尔可夫模型

 隐马尔可夫模型实现的是序列化的建模，它打破了对数据独立同分布的固有假设，侧重于**时序上的依赖关系**。 

>  在自然语言和金融市场数据这类时间序列（time series）中，某个数据往往会受到之前数据的影响，这种情况下还要强行套用独立同分布假设的话，肯定不会符合实际情况。 



 **隐马尔可夫模型则是通过隐藏状态生成观测序列的马尔可夫过程**。

- 在简单的马尔可夫链（Markov  chain）里，所有状态是都直接可见的，因此状态转移概率是唯一的参数。
- 在**隐马尔可夫模型**中，状态本身不是直接可见的，可见的是取决于状态的输出。由于每个状态都有和输出相关的**概率分布**，因而隐马尔可夫模型的输出就能够提供**关于隐藏状态的信息**。 



 隐藏的序列叫作状态序列（state sequence） ； 可见的序列叫作观测序列（observation sequence） 。



#### **齐次马尔可夫过程**：

在某一时刻的选择只取决于前一时刻的选择，而与之前所有时刻的选择都没有关系，这个状态变化的过程就是**齐次马尔可夫过程**（homogeneous Markov process）。 



#### **观测独立性：**

在观测时，任意时刻的观测只取决于当时的状态，而与其他的状态和观测无关，这样的隐马尔可夫模型就满足**观测独立性**（observation independence）。 





### 隐马尔可夫模型的三要素**

 假设所有可能的状态 $q_i$ 总共有 $N$ 个，所有可能的观测结果 $v_j$ 总共有 $M$ 个 。

 在第一个时刻的状态选择中，每个状态会被赋予一个初始概率（initial probability）$\pi_i = P(i_1 =  q_i)$，这些初始概率共同组成了初始状态概率向量（initial state distribution）$\boldsymbol \pi$。 

 随着时序的推移，系统的状态也会不断变化，从上一个状态 $q_i$ 跳转到下一个状态 $q_j$ 的概率 $a_{ij} = P(i_{t +  1} = q_j | i_t = q_i)$ 叫做**转移概率**（transition  probability），所有状态转移概率组成一个维度和状态数目相同的 $N$ 维对称方阵 $\bf  A$，这个矩阵就是状态转**移概率矩阵**（transition probability matrix）。 

 状态和观测不是一一对应的关系，一个状态会按照概率分布产生不同的观测。在某一时刻，状态 $q_j$ 生成观测 $v_k$ 的概率 $b_j(k) = P(o_t = v_k | i_t = q_j)$ 叫作发射概率，或者**观测概率**（emission probability）。  观测的概率共同形成了 $N \times M$ 维的**观测概率矩阵** $\bf B$（emission probaility matrix）。



 **初始状态概率向量、状态转移概率矩阵和观测概率矩阵共同构成了隐马尔可夫模型的三要素**。初始状态概率向量确定了隐马尔可夫模型的结构，状态转移概率矩阵生成了隐藏的状态序列，观测概率矩阵则确定了如何从状态生成观测。  



 在隐马尔可夫模型中，表示隐藏的状态的变量也叫隐变量（latent variable）。 

>  隐马尔可夫模型通过引入隐变量将输出，也就是观测之间的马尔可夫性转移成**隐变量**之间的马尔可夫性，虽然没有明显地增加参数的数目，却能表示**输出之间更复杂的依赖关系**。这种结构也被称为**状态空间模型**（state space model），广泛应用在信号分析和控制论等其他领域中。 



## 混合模型

 从数据生成的角度看，隐马尔可夫模型又可以看成是一种推广的混合模型。

同样的观测结果可能来自于不同的状态，因此可以看成是**不同状态的混合**，每一个状态都对应着混合结果中的一个成分。只不过其中不同的成分不是相互独立的，它们由马尔可夫链所定义的依赖关系联系起来。 



 **混合模型**（mixture  model）是由若干个成分构成的概率模型，每个成分都来自一个独立的概率分布。

在总体中采出来的每个样本都是多个成分的混合。虽然不能准确地确定单个样本来自于哪个成分，但通过多个样本的统计特性可以推断出每个混合成分的特征。(soft margin)

> 最常见的混合模型是高斯混合模型（Gaussian mixture model），其中的每个成分都是高斯分布。 



##  **生成模型**

 **隐马尔可夫模型属于生成模型**，可以从贝叶斯的角度加以审视。

隐马尔可夫的三要素共同定义了状态和观测的联合分布，其中**转移概率**相当于**隐藏状态的先验分布**，而**观测概率**相当于**已知状态的条件下观测的似然分布**。 



 由于转移概率本身是多取值的分类分布（categorical distribution），因此自然的思路是将转移概率的先验设置为**狄利克雷分布**，也就是分类分布（categorical distribution）的共轭先验。 



### 狄利克雷先验分布的参数

狄利克雷分布中有一系列的参数 $\alpha_i$：如果所有参数的取值都相等，这样的分布就是对称狄利克雷分布（symmetric Dirichlet distribution）。这种分布也可以看成是**无先验的分布**，并不能反映出哪些状态比其他状态更可能出现。

浓度参数（concentration parameter），能够决定转移矩阵的稀疏程度。小于 1 的浓度参数对应的转移矩阵是稀疏矩阵，向部分位置聚集。

> 其中对于每个给定的源状态，只有少数目标状态具有不可忽略的转移概率。
>
>  如果一个狄利克雷分布还不够，那还可以使用层次化的狄利克雷分布。在两级先验中，上层分布（the upper  distribution）控制着下层分布（the lower  distribution）的参数，下层分布再来继续控制转移概率。

上层分布起到的就是**无信息先验**的作用，可以**决定哪些状态更容易出现**

**浓度参数**决定了**状态的密度**。 



##  **条件随机场**（conditional random field） 简述

 **隐马尔可夫模型是生成模型，其在判别模型中的对应是条件随机场**（conditional random field）。

条件随机场融合了马尔可夫随机场的**无向图特性**和隐马尔可夫模型的**条件特性**，如果将上图中隐马尔可夫模型中的**有向边都改成无向边**，就形成了线性链（linear chain）条件随机场。 



 线性链条件场将**状态定义为可见的输入**，**发射概率和转移概率**也被重新定义为**特征函数**（feature function）。

特征函数可以用来计算给定输入时，输出的条件概率，进而实现判别。 



## 应用

 在 Python 中有一个专门实现隐马尔可夫模型的库 hmmlearn，这个库原本是 Scikit-learn 中的一个模块。

> 使用的例子是根据英超近 15 个赛季曼市德比的结果构造出的隐马尔可夫模型，其中状态变量被设定为主客场，有 2 个取值；观测变量则被设定为曼城方的比赛结果，有胜平负 3 个取值；模型的三要素可以根据 30 场比赛的结果统计出来。
>
> 在未知 2018-19 赛季英超日程安排，也就是不知道主客场这个隐变量的条件下，利用隐马尔可夫模型也能估计两场曼市德比的胜负。

```python
import numpy as np
import math
from hmmlearn.hmm import MultinomialHMM

model_man_derby = MultinomialHMM(n_components=2)
states = ["Home", "Away"]
observations = ["Win", "Lose", "Draw"]

initial_vector = np.array([0.5, 0.5])
model_man_derby.startprob_ = initial_vector
transition_matrix = np.array([[0.2, 0.8], [0.8, 0.2]])
model_man_derby.transmat_ = transition_matrix
emission_matrix = np.array([[0.4, 0.467, 0.133], [0.4, 0.4, 0.2]])
model_man_derby.emissionprob_ = emission_matrix

result = np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1],
                   [1, 2], [2, 0], [2, 1], [2, 2]]).T
titles = ["WW", "WL", "WD", "LW", "LL", "LD", "DW", "DL", "DD"]
i = 0

for title in titles:
    logprob = model_man_derby.score(result[:, i].reshape(1, -1))
    print(title, ':', math.exp(logprob))
    i += 1
```



## 总结

- 隐马尔可夫模型由隐藏的状态序列和可见的观测序列构成，能够对时序依赖关系建模；
- 隐马尔可夫模型的定量描述包括初始状态向量、状态转移矩阵和观测矩阵三部分；
- 作为生成模型，隐马尔可夫可以视为混合模型的推广；
- 隐马尔可夫模型的判别方法对应是条件随机场。

隐马尔可夫模型最主要用于自然语言处理莫属，语音和文字之间有天然的时序关联。